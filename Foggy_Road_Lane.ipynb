{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzEWrNp1ETj9"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "def dark_channel(image, size=15):\n",
    "    \"\"\"Calculate the dark channel prior of an image.\"\"\"\n",
    "    min_channel = np.min(image, axis=2)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (size, size))\n",
    "    dark_channel = cv2.erode(min_channel, kernel)\n",
    "    return dark_channel\n",
    "\n",
    "def estimate_atmospheric_light(image, dark_channel):\n",
    "    \"\"\"Estimate atmospheric light based on the dark channel.\"\"\"\n",
    "    h, w = dark_channel.shape\n",
    "    num_pixels = h * w\n",
    "    num_brightest_pixels = int(max(num_pixels // 1000, 1))  # Top 0.1% brightest pixels\n",
    "    indices = np.unravel_index(np.argsort(dark_channel.ravel())[-num_brightest_pixels:], dark_channel.shape)\n",
    "    A = np.mean(image[indices], axis=0)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqT2EwEbEdGL"
   },
   "outputs": [],
   "source": [
    "def defog_image(image):\n",
    "    \"\"\"Defog the input image using improved dark channel prior.\"\"\"\n",
    "    I = image.astype(float)\n",
    "    dark_channel_img = dark_channel(I)\n",
    "    A = estimate_atmospheric_light(I, dark_channel_img)\n",
    "    omega = 0.95\n",
    "    t = 1 - omega * (dark_channel_img / np.max(A))  # Normalize by max atmospheric light value\n",
    "    t = np.clip(t, 0.1, 1)  # Avoid division by zero\n",
    "    t = cv2.bilateralFilter(t.astype(np.float32), 5, 0.1, 0.1)\n",
    "    J = np.empty_like(I)\n",
    "    for i in range(3):  # For each color channel\n",
    "        J[:, :, i] = (I[:, :, i] - A[i]) / t + A[i]\n",
    "    J = np.clip(J, 0, 255).astype(np.uint8)  # Ensure pixel values are valid\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofdI3B_xEjnP"
   },
   "outputs": [],
   "source": [
    "def detect_lines(cropped_edges, image):\n",
    "    \"\"\"Detect lines in the cropped edges image and return the line image.\"\"\"\n",
    "    lines = cv2.HoughLinesP(cropped_edges, rho=1, theta=np.pi / 180, threshold=50, minLineLength=100, maxLineGap=50)\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    line_image = np.zeros_like(image)\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            # Calculate the slope of the line\n",
    "            if x2 != x1:  # Avoid division by zero for vertical lines\n",
    "                slope = (y2 - y1) / (x2 - x1)\n",
    "            else:\n",
    "                slope = np.inf  # Assign infinite slope for vertical lines\n",
    "\n",
    "            # Filter out vertical lines (considered vertical if slope is steep)\n",
    "            if abs(slope) > 0.5:  # Adjust this threshold to filter out nearly vertical lines\n",
    "                cv2.line(line_image, (x1, y1), (x2, y2), (0, 255, 0), 5)  # Draw lane lines\n",
    "\n",
    "    return line_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JM0ETtvsEq6h"
   },
   "outputs": [],
   "source": [
    "def detect_lanes(image):\n",
    "    \"\"\"Detect lanes in a defogged image while filtering out vertical lines.\"\"\"\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    cv2_imshow(gray)  # Show grayscale image\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    cv2_imshow(blur)  # Show blurred image\n",
    "\n",
    "    # Edge detection using Canny\n",
    "    edges = cv2.Canny(blur, 50, 150)\n",
    "    cv2_imshow(edges)  # Show edges\n",
    "\n",
    "    # Define a refined region of interest (ROI) mask to focus on the lane area\n",
    "    height, width = edges.shape\n",
    "    mask = np.zeros_like(edges)\n",
    "    polygon = np.array([[  # Define the polygon to mask the region of interest\n",
    "        (0, height),\n",
    "        (width, height),\n",
    "        (width, height // 1.7),  # Higher point to focus more on the lanes\n",
    "        (0, height // 1.7)\n",
    "    ]], np.int32)\n",
    "    cv2.fillPoly(mask, polygon, 255)\n",
    "    cropped_edges = cv2.bitwise_and(edges, mask)\n",
    "    cv2_imshow(cropped_edges)  # Show cropped edges\n",
    "\n",
    "    # Call detect_lines to get the line image\n",
    "    line_image = detect_lines(cropped_edges, image)\n",
    "\n",
    "    # Combine line image with the original image\n",
    "    lane_image = cv2.addWeighted(image, 0.8, line_image, 1, 1)\n",
    "\n",
    "    return lane_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t27DFFGHFiPe"
   },
   "outputs": [],
   "source": [
    "foggy_image = cv2.imread(\"/images.png\")\n",
    "\n",
    "cv2_imshow(foggy_image)\n",
    "# Step 1: Defog the image\n",
    "defogged_image = defog_image(foggy_image)\n",
    "cv2_imshow(defogged_image)  # Show defogged image\n",
    "\n",
    "# Step 2: Detect lanes on the defogged image\n",
    "lane_image = detect_lanes(defogged_image)\n",
    "\n",
    "# Display the final result\n",
    "cv2_imshow(lane_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "def add_haze(image, haze_intensity=0.7, light_intensity=0.8):\n",
    "    \"\"\"\n",
    "    Add synthetic haze to an image.\n",
    "\n",
    "    Parameters:\n",
    "        image (np.array): Input clear image (BGR format).\n",
    "        haze_intensity (float): Intensity of the haze (0 to 1).\n",
    "        light_intensity (float): Intensity of atmospheric light (0 to 1).\n",
    "\n",
    "    Returns:\n",
    "        hazy_image (np.array): Hazy image.\n",
    "    \"\"\"\n",
    "    h, w, c = image.shape\n",
    "\n",
    "    # Create a uniform transmission map to simulate haze\n",
    "    transmission_map = np.full((h, w), 1 - haze_intensity, dtype=np.float32)\n",
    "    transmission_map = transmission_map[:, :, np.newaxis]  # Expand dimensions for broadcasting\n",
    "\n",
    "    # Atmospheric light\n",
    "    A = np.full((1, 1, c), light_intensity * 255, dtype=np.float32)\n",
    "\n",
    "    # Apply haze model\n",
    "    hazy_image = image.astype(np.float32) * transmission_map + A * (1 - transmission_map)\n",
    "    hazy_image = np.clip(hazy_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return hazy_image\n",
    "\n",
    "# Load an image\n",
    "image = cv2.imread('/19.jpg')  # Replace with your image path\n",
    "\n",
    "# Add haze\n",
    "hazy_image = add_haze(image, haze_intensity=0.89, light_intensity=0.9)\n",
    "\n",
    "# Display the images\n",
    "cv2_imshow(image)\n",
    "cv2_imshow(hazy_image)\n",
    "\n",
    "# Wait for a key press and close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
